# üéØ Syst√®me d'Analyse de Sentiments Client

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/)
[![Flask](https://img.shields.io/badge/Flask-3.1.2-green.svg)](https://flask.palletsprojects.com/)
[![scikit-learn](https://img.shields.io/badge/scikit--learn-1.6.1-orange.svg)](https://scikit-learn.org/)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

## üìã Description

Syst√®me automatis√© d'analyse de sentiments clients bas√© sur le Machine Learning et le NLP (Natural Language Processing). Ce projet permet de classifier automatiquement les avis clients en sentiments **Positifs** ou **N√©gatifs** avec une pr√©cision de **98,07%**.

### ‚ú® Fonctionnalit√©s Principales

- ü§ñ **Classification automatique** : Analyse de sentiments en temps r√©el
- üìä **Dashboard interactif** : Visualisation des statistiques et tendances
- üìù **Historique des pr√©dictions** : Suivi complet de toutes les analyses
- üîî **Monitoring r√©actif** : Alertes automatiques si ratio n√©gatif > seuil critique
- üöÄ **Performance optimale** : 98,07% d'accuracy avec Linear SVM
- ‚ö° **Temps de r√©ponse** : < 100ms par pr√©diction

### üéì Contexte Acad√©mique

Ce projet a √©t√© d√©velopp√© dans le cadre d'un projet de Machine Learning et NLP.

---

## üèóÔ∏è Architecture du Projet

```
sentiment-analysis/
‚îÇ
‚îú‚îÄ‚îÄ app.py                     # Application Flask principale
‚îú‚îÄ‚îÄ config.py                  # Configuration de l'app
‚îú‚îÄ‚îÄ run.py                     # Script de lancement
‚îú‚îÄ‚îÄ requirements.txt           # D√©pendances Python
‚îú‚îÄ‚îÄ nixpacks.toml              # Configuration pour le d√©ploiement (Railway/Render)
‚îú‚îÄ‚îÄ Procfile                   # Commande pour serveur Gunicorn
‚îú‚îÄ‚îÄ .gitattributes             # Configuration Git LFS (pour les .pkl)
‚îÇ
‚îú‚îÄ‚îÄ Data/
‚îÇ   ‚îî‚îÄ‚îÄ raw/
‚îÇ       ‚îî‚îÄ‚îÄ processed/
‚îÇ           ‚îî‚îÄ‚îÄ vectorization_objects.pkl 
‚îÇ
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îî‚îÄ‚îÄ final_optimized_model.pkl          
‚îÇ
‚îî‚îÄ‚îÄ templates/                 # Dossier des vues HTML
    ‚îú‚îÄ‚îÄ base.html
    ‚îú‚îÄ‚îÄ index.html
    ‚îú‚îÄ‚îÄ history.html
    ‚îú‚îÄ‚îÄ stats.html
    ‚îî‚îÄ‚îÄ about.html
```

---

## üîß Installation

### Pr√©requis

- **Python 3.8+** (recommand√© : Python 3.9 ou 3.10)
- **pip** (gestionnaire de paquets Python)
- **virtualenv** (recommand√© pour isolation)

### √âtape 1 : Cloner le Repository

```bash
git clone https://github.com/votre-username/sentiment-analysis.git
cd sentiment-analysis
```

### √âtape 2 : Cr√©er un Environnement Virtuel

**Linux / macOS :**
```bash
python3 -m venv venv
source venv/bin/activate
```

**Windows :**
```bash
python -m venv venv
venv\Scripts\activate
```

### √âtape 3 : Installer les D√©pendances

```bash
pip install --upgrade pip
pip install -r requirements.txt
```

> **‚ö†Ô∏è Note importante** : Les packages `gensim` et `textblob` doivent √™tre install√©s en dernier comme sp√©cifi√© dans `requirements.txt`.

### √âtape 4 : T√©l√©charger les Ressources NLP

Apr√®s l'installation, t√©l√©chargez les ressources n√©cessaires pour TextBlob :

```bash
python -m textblob.download_corpora
```

Si vous utilisez NLTK directement, t√©l√©chargez √©galement :

```python
import nltk
nltk.download('stopwords')
nltk.download('wordnet')
nltk.download('punkt')
```

### √âtape 5 : Configuration (Optionnel)

Cr√©ez un fichier `.env` pour les variables d'environnement :

```bash
# .env
FLASK_APP=app.py
FLASK_ENV=development
SECRET_KEY=votre_cl√©_secr√®te_ici
DATABASE_URI=sqlite:///data/predictions.db
```

---

## üöÄ Utilisation

### D√©marrage en Mode D√©veloppement

```bash
python app.py
```

L'application sera accessible √† l'adresse : **http://localhost:5000**

---

## üîç Pipeline de Traitement

### 1. Pr√©traitement NLP

```python
# √âtapes automatis√©es :
1. Conversion en minuscules
2. Suppression ponctuation et caract√®res sp√©ciaux
3. Tokenisation
4. Retrait des stopwords
5. Lemmatisation (WordNet)
6. Gestion des n√©gations (not_good ‚Üí single token)
```

### 2. Vectorisation TF-IDF

```python
# Param√®tres optimis√©s :
- max_features: 10,000
- min_df: 5
- max_df: 0.7
- ngram_range: (1, 2)  # Unigrammes + Bigrammes
```

### 3. Classification Linear SVM

```python
# Hyperparam√®tres optimaux (GridSearchCV) :
- C: 1.0
- kernel: 'linear'
- class_weight: None
```

---

## üì¶ D√©pendances Principales

### Web Framework
- **Flask 3.1.2** : Framework web l√©ger et flexible
- **Werkzeug 3.1.3** : WSGI utilities
- **Jinja2 3.1.6** : Moteur de templates
- **Gunicorn 21.2.0** : Serveur WSGI pour production

### Machine Learning
- **scikit-learn 1.6.1** : Biblioth√®que ML principale
- **numpy 2.1.3** : Calculs num√©riques
- **pandas 2.2.3** : Manipulation de donn√©es
- **scipy 1.15.2** : Algorithmes scientifiques
- **joblib 1.4.2** : S√©rialisation des mod√®les

### NLP (Natural Language Processing)
- **gensim** : Word2Vec et mod√®les de topics
- **textblob** : Analyse de sentiments et POS tagging

### Utilitaires
- **requests 2.32.3** : Requ√™tes HTTP
- **python-dateutil 2.9.0** : Manipulation de dates
- **pytz 2025.1** : Gestion des fuseaux horaires

---

## üë• Auteurs & Contributeurs

Ce projet est le fruit d'une collaboration passionn√©e entre :

* **Akilou Illa Abdourazak** : [Abdourazak01](https://github.com/Abdourazak01)
* **Yassine Boumhand** : [Yboumhand](https://github.com/Yboumhand)

## ü§ù Contribution

Les contributions sont les bienvenues ! Voici comment contribuer :

1. **Fork** le projet
2. Cr√©ez une **branche** pour votre fonctionnalit√© (`git checkout -b feature/AmazingFeature`)
3. **Committez** vos changements (`git commit -m 'Add AmazingFeature'`)
4. **Push** vers la branche (`git push origin feature/AmazingFeature`)
5. Ouvrez une **Pull Request**
---

## ‚≠ê Si ce projet vous a √©t√© utile

N'h√©sitez pas √† lui donner une ‚≠ê sur GitHub !

---

**Derni√®re mise √† jour** : 7 F√©vrier 2025
**Version** : 1.0.0
